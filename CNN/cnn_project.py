# -*- coding: utf-8 -*-
"""CNN_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1avZrkVJedBuVCR98VDHxGm1iZSIxn4eZ
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import os
import glob
import cv2
import PIL
import PIL.Image
import tensorflow as tf
import tensorflow_datasets as tfds

"""# #Loading Data"""

!ls "/content/drive/MyDrive/Colab Notebooks/data/image"

"""extract data from zip file"""

#extract data from zip file
!ls
!7za -y x "/content/drive/MyDrive/Colab Notebooks/data/image/origin.7z.*"

#Creating folder in Drive "Preprocessesed_data"
!mkdir "/content/drive/MyDrive/Colab Notebooks/preprocessed_data"

#Copy extract Origin folder of Images in Preprocessed_data

!cp -r ./origin "/content/drive/MyDrive/Colab Notebooks/preprocessed_data"

"""### **Importing Labels**"""

labels = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/data/label/label.lst", delimiter=" ",
                    names=['image_name', 'face_id_in_image', 'face_box_top', 'face_box_left', 'face_box_right',
                           'face_box_bottom', 'face_box_cofidence', 'expression_label'] )
labels.head()

mapper = {
0: "angry",
1: "disgust",
2: "fear",
3: "happy",
4: "sad",
5: "surprise",
6: "neutral"}

class_names = ["angry", "disgust", "fear", "happy", "sad", "surprise","neutral"]

"""### Creating Sub-Directories according to class_names"""

import shutil
for name in class_names:
  os.makedirs(os.path.join("/content/drive/MyDrive/Colab Notebooks/preprocessed_data/final_data", name), exist_ok=True)

# shutil.copy("/content/drive/MyDrive/Colab Notebooks/preprocessed_data/samples/afraid_African_214.jpg", "/content/drive/MyDrive/Colab Notebooks/preprocessed_data/angry")

"""### Move all images from main directory to sub-directories according to emotion_label and image_name"""

import os
from tqdm import tqdm
import shutil
import time

origin_folder_path = r"/content/drive/MyDrive/Colab Notebooks/preprocessed_data/origin"
final_data_path = r"/content/drive/MyDrive/Colab Notebooks/preprocessed_data/final_data"

# Make sure 'labels' DataFrame is properly defined with 'expression_label' and 'image_name' columns
# Make sure 'mapper' dictionary is properly defined with emotion labels as keys and emotion names as values

# Sample 'labels' DataFrame for demonstration purposes:
# labels = pd.DataFrame({'expression_label': ['happy', 'sad', 'happy', 'angry'],
#                        'image_name': ['img1.jpg', 'img2.jpg', 'img3.jpg', 'img4.jpg']})


for label in tqdm(labels.expression_label.unique()):
    df_lbl = labels[labels.expression_label == label]
    emotion_name = mapper[label]

    # Create destination directory for each emotion
    dest_path = os.path.join(final_data_path, emotion_name)
    os.makedirs(dest_path, exist_ok=True)

    # Move images for the emotion
    for image_name in df_lbl.image_name:
        img = os.path.join(origin_folder_path, image_name)
        if os.path.exists(img):
            dest_file = os.path.join(dest_path, image_name)
            if os.path.exists(dest_file):
                # Append a timestamp to the filename to make it unique
                timestamp = str(int(time.time()))
                dest_file = os.path.join(dest_path, f"{image_name.split('.')[0]}_{timestamp}.{image_name.split('.')[-1]}")
            shutil.move(img, dest_file)

    print(f"Moved emotion '{emotion_name}' with {len(df_lbl)} images to '{dest_path}'.")

from tensorflow.keras.utils import image_dataset_from_directory

data = image_dataset_from_directory("/content/drive/MyDrive/Colab Notebooks/preprocessed_data/final_data")

"""### Path of Data Directory"""

import pathlib

data_dir = pathlib.Path("/content/drive/MyDrive/Colab Notebooks/preprocessed_data/final_data")
data_dir

"""Each directory contains images of that type of emotion. Here is angry image shown below:"""

angry = list(data_dir.glob('angry/*'))
PIL.Image.open(str(angry[55]))

batch_size = 64
img_height = 224
img_width = 224

"""# Split the dataset into training and validation sets:


> Traning data is 80%


> Validation data is 20%




"""

#Traning Data
train_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

#Validation Dataset
val_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

"""### **Visualize the data**
# Here are the first nine images from the training dataset.
"""

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

"""### NORMALIZATION"""

normalization_layer = tf.keras.layers.Rescaling(1./255)

normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
image_batch, labels_batch = next(iter(normalized_ds))
first_image = image_batch[0]
# Notice the pixel values are now in `[0,1]`.
print(np.min(first_image), np.max(first_image))

AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

"""### Load the pre-trained MobileNetV2 model without the top classification layer"""

import tensorflow as tf
import pathlib
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import layers, models

base_model = MobileNetV2(input_shape=(img_height, img_width, 3),
                         include_top=False,
                         weights='imagenet')

# Freeze the base model to prevent its weights from being updated during training
base_model.trainable = False

# base_model.summary()

"""### Add a new classification head to the model"""

num_classes = 7
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(num_classes, activation='softmax')
])

model.summary() # For checking model summary

"""### Compile the model"""

model.compile(
  optimizer='adam',
  loss=tf.keras.losses.SparseCategoricalCrossentropy(),
  metrics=['accuracy'])

for image, label in train_ds.take(5):
    print(image.shape, label)

"""

Train the model"""

model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=30
)

"""### **validation loss and accuracy.**"""

# Evaluate the model on the validation dataset
loss, accuracy = model.evaluate(val_ds)
print(f"Validation Loss: {loss}")
print(f"Validation Accuracy: {accuracy}")